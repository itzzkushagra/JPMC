{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 61542,
          "databundleVersionId": 6888007,
          "sourceType": "competition"
        },
        {
          "sourceId": 6977472,
          "sourceType": "datasetVersion",
          "datasetId": 4005256
        },
        {
          "sourceId": 5902,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4675
        },
        {
          "sourceId": 5905,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4678
        },
        {
          "sourceId": 5913,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4686
        },
        {
          "sourceId": 5916,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4689
        },
        {
          "sourceId": 5950,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4723
        }
      ],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itzzkushagra/JPMC/blob/main/Kushagra_llm_detect_ai_generated_text_nn_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After running this cell, you'll be prompted to authenticate and authorize Google Drive access.\n",
        "\n",
        "# Now, you can access your Google Drive content under the '/content/drive' directory in Colab.\n",
        "# You can create, read, and write files in this directory, making it a convenient way to store and retrieve data.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOQr0GUb88-K",
        "outputId": "d9ee299d-334a-49fa-f392-7a627dffd27b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div style=\"padding:20px;\n",
        "            color:#150d0a;\n",
        "            margin:10px;\n",
        "            font-size:220%;\n",
        "            text-align:center;\n",
        "            display:fill;\n",
        "            border-radius:20px;\n",
        "            border-width: 5px;\n",
        "            border-style: solid;\n",
        "            border-color: #150d0a;\n",
        "            background-color:#4FC95F;\n",
        "            overflow:hidden;\n",
        "            font-weight:500\">LLM - Detect AI Generated Text</div>"
      ],
      "metadata": {
        "id": "06gSeiBWeBpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LIBRARIES\n",
        "!pip install keras_core\n",
        "# Global\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import regex as re\n",
        "\n",
        "# Function to plot WordCloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter\n",
        "\n",
        "# Tensorflow/Keras\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "from keras import layers, Sequential\n",
        "from keras.layers import TextVectorization\n",
        "from keras.callbacks import (ModelCheckpoint,\n",
        "                             EarlyStopping,\n",
        "                             ReduceLROnPlateau,\n",
        "                             CSVLogger,\n",
        "                             LearningRateScheduler)\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
        "                             classification_report, precision_recall_curve,\n",
        "                             roc_curve, auc)\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "# Set Seed for Reproducibility\n",
        "keras.utils.set_random_seed(42)\n",
        "\n",
        "# Use mixed precision to speed up all training.\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "\n",
        "# Check Versions\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Keras:\", keras.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:13.909024Z",
          "iopub.execute_input": "2024-01-13T19:17:13.912164Z",
          "iopub.status.idle": "2024-01-13T19:17:35.464156Z",
          "shell.execute_reply.started": "2024-01-13T19:17:13.912096Z",
          "shell.execute_reply": "2024-01-13T19:17:35.463131Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7etgIDbeBp7",
        "outputId": "1d0e9a96-904d-4719-91f5-3b5fb69cf09a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_core in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_core) (13.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_core) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_core) (0.1.2)\n",
            "TensorFlow: 2.15.0\n",
            "Keras: 0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def compress(df, verbose=True):\n",
        "    \"\"\"\n",
        "    Reduces the size of the DataFrame by downcasting numerical columns\n",
        "    \"\"\"\n",
        "    input_size = df.memory_usage(index=True).sum() / (1024 ** 2)\n",
        "    if verbose:\n",
        "        print(\"Old dataframe size:\", round(input_size, 2), 'MB')\n",
        "\n",
        "    in_size = df.memory_usage(index=True).sum()\n",
        "    dtype_before = df.dtypes.copy()  # Copy of original data types\n",
        "\n",
        "    for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "        col_type = df[col].dtype\n",
        "        col_min, col_max = df[col].min(), df[col].max()\n",
        "\n",
        "        if col_type == 'int64':\n",
        "            if col_min > np.iinfo(np.int8).min and col_max < np.iinfo(np.int8).max:\n",
        "                df[col] = df[col].astype(np.int8)\n",
        "            elif col_min > np.iinfo(np.int16).min and col_max < np.iinfo(np.int16).max:\n",
        "                df[col] = df[col].astype(np.int16)\n",
        "            elif col_min > np.iinfo(np.int32).min and col_max < np.iinfo(np.int32).max:\n",
        "                df[col] = df[col].astype(np.int32)\n",
        "            elif col_min > np.iinfo(np.int64).min and col_max < np.iinfo(np.int64).max:\n",
        "                df[col] = df[col].astype(np.int64)\n",
        "        elif col_type == 'float64':\n",
        "            ## float16 warns of overflow\n",
        "            # if col_min > np.finfo(np.float16).min and col_max < np.finfo(np.float16).max:\n",
        "            #     df[col] = df[col].astype(np.float16)\n",
        "            if col_min > np.finfo(np.float32).min and col_max < np.finfo(np.float32).max:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "            elif col_min > np.finfo(np.float64).min and col_max < np.finfo(np.float64).max:\n",
        "                df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    out_size = df.memory_usage(index=True).sum()\n",
        "    ratio = (1 - round(out_size / in_size, 2)) * 100\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Optimized size by {}%\".format(round(ratio, 2)))\n",
        "        print(\"New DataFrame size:\", round(out_size / (1024 ** 2), 2), \"MB\")\n",
        "\n",
        "    # Filter only numerical columns for comparison\n",
        "    numeric_columns = df.select_dtypes(include=['float32', 'float64', 'int8', 'int16', 'int32', 'int64'])\n",
        "    dtype_after = numeric_columns.dtypes.copy()  # Copy of data types after compression\n",
        "\n",
        "    # Create a comparison DataFrame\n",
        "    comparison_df = pd.DataFrame({'Before': dtype_before[numeric_columns.columns], 'After': dtype_after})\n",
        "    comparison_df['Size Reduction'] = ratio\n",
        "\n",
        "    return df, comparison_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.465587Z",
          "iopub.execute_input": "2024-01-13T19:17:35.466208Z",
          "iopub.status.idle": "2024-01-13T19:17:35.479352Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.466181Z",
          "shell.execute_reply": "2024-01-13T19:17:35.478435Z"
        },
        "trusted": true,
        "id": "PtZIB-95eBp_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate WordCloud\n",
        "\n",
        "def generate_wordcloud_subplot(df, label_value, subplot_position, max_words=1000, width=800, height=400, top_n = 10):\n",
        "    \"\"\"\n",
        "    Generate a word cloud for a specific label value and display it in a subplot.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The DataFrame containing text data and labels.\n",
        "        label_value (int): The label value for which to generate the word cloud.\n",
        "        subplot_position (int): The position of the subplot where the word cloud will be displayed.\n",
        "        max_words (int, optional): Maximum number of words to include in the word cloud. Default is 1000.\n",
        "        width (int, optional): Width of the word cloud image. Default is 800.\n",
        "        height (int, optional): Height of the word cloud image. Default is 400.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Select the text subset for the specified label value\n",
        "    text_subset = df[df.generated == label_value].text\n",
        "\n",
        "    # Define stopwords to be excluded\n",
        "    stopwords = set(STOPWORDS)\n",
        "\n",
        "    # Create a WordCloud object with specified parameters\n",
        "    wc = WordCloud(max_words=max_words, width=width, height=height, stopwords=stopwords)\n",
        "\n",
        "    # Generate the word cloud from the selected text subset\n",
        "    wc.generate(\" \".join(text_subset))\n",
        "\n",
        "    # Create a subplot and display the word cloud\n",
        "    plt.subplot(subplot_position)\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "\n",
        "    # Set the title for the word cloud plot\n",
        "    title = f'WordCloud for Label {label_value} ({(\"Student\" if label_value == 0 else \"AI\")})'\n",
        "    plt.title(title)\n",
        "\n",
        "    # Count occurrences of words in the text subset\n",
        "    words_count = Counter(\" \".join(text_subset).split())\n",
        "    top_words = words_count.most_common(top_n)\n",
        "    bottom_words = words_count.most_common()[:-top_n-1:-1]  # Extract least common words\n",
        "\n",
        "    # Print the most common words\n",
        "    print(f\"Top {top_n} words for Label {label_value}:\")\n",
        "    for idx, (word, count) in enumerate(top_words, start=1):\n",
        "        print(f\"{idx}. {word}: {count} times\")\n",
        "    print(\"------------------------------\")\n",
        "\n",
        "    # Print the least common words\n",
        "    print(f\"Least {top_n} words for Label {label_value}:\")\n",
        "    for idx, (word, count) in enumerate(bottom_words, start=1):\n",
        "        print(f\"{idx}. {word}: {count} times\")\n",
        "    print(\"------------------------------\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.480654Z",
          "iopub.execute_input": "2024-01-13T19:17:35.480937Z",
          "iopub.status.idle": "2024-01-13T19:17:35.516070Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.480913Z",
          "shell.execute_reply": "2024-01-13T19:17:35.514019Z"
        },
        "trusted": true,
        "id": "d5lD1uZEeBp_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Data\n",
        "\n",
        "data_path = '/content/drive/MyDrive/data_vlg'\n",
        "\n",
        "for dirname, _, filenames in os.walk(data_path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.518411Z",
          "iopub.execute_input": "2024-01-13T19:17:35.518716Z",
          "iopub.status.idle": "2024-01-13T19:17:35.536778Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.518692Z",
          "shell.execute_reply": "2024-01-13T19:17:35.535556Z"
        },
        "trusted": true,
        "id": "7tU9QVsceBqB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we load the train dataset we see that it contains 1378 essays."
      ],
      "metadata": {
        "id": "T_5hrfAneBqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essays Train Dataset\n",
        "\n",
        "df_train_essays = pd.read_csv('/content/drive/MyDrive/train_essays.csv')\n",
        "\n",
        "print(df_train_essays.info())\n",
        "df_train_essays.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.538548Z",
          "iopub.execute_input": "2024-01-13T19:17:35.539204Z",
          "iopub.status.idle": "2024-01-13T19:17:35.675533Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.539178Z",
          "shell.execute_reply": "2024-01-13T19:17:35.674110Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "tNjt8jMFeBqG",
        "outputId": "6777ee76-a415-47ce-f377-bcc29a0c3c07"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/train_essays.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cdff00e6b4eb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Essays Train Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_train_essays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/train_essays.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_essays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/train_essays.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compression\n",
        "\n",
        "# Compress dataframe\n",
        "df_train_essays, comparison_df = compress(df_train_essays, verbose=True)\n",
        "\n",
        "# Check compression\n",
        "comparison_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.677061Z",
          "iopub.execute_input": "2024-01-13T19:17:35.678152Z",
          "iopub.status.idle": "2024-01-13T19:17:35.701893Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.678110Z",
          "shell.execute_reply": "2024-01-13T19:17:35.701009Z"
        },
        "trusted": true,
        "id": "VkUvjYMveBqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first essay text\n",
        "\n",
        "df_train_essays.text[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.703224Z",
          "iopub.execute_input": "2024-01-13T19:17:35.703895Z",
          "iopub.status.idle": "2024-01-13T19:17:35.710844Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.703865Z",
          "shell.execute_reply": "2024-01-13T19:17:35.709539Z"
        },
        "trusted": true,
        "id": "7Y9r48ObeBqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='289C4E'>3.1.2. Test Set üß™<font><a class='anchor' id='essaystest'></a> [‚Üë](#top)"
      ],
      "metadata": {
        "id": "F6hvOEG5eBqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we load the test dataset we see that it only contains 3 essays. Additionally, the text only contains 12 characters. However the test set used for evaluation contains more essays."
      ],
      "metadata": {
        "id": "eyzekkl2eBqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essays Test Dataset\n",
        "\n",
        "df_test_essays = pd.read_csv('/content/drive/MyDrive/data_vlg /test_essays.csv')\n",
        "\n",
        "print(df_test_essays.info())\n",
        "df_test_essays.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.712676Z",
          "iopub.execute_input": "2024-01-13T19:17:35.713171Z",
          "iopub.status.idle": "2024-01-13T19:17:35.736064Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.713130Z",
          "shell.execute_reply": "2024-01-13T19:17:35.734830Z"
        },
        "trusted": true,
        "id": "yRDkdQjMeBqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compression\n",
        "\n",
        "# Compress dataframe\n",
        "df_test_essays, comparison_df = compress(df_test_essays, verbose=True)\n",
        "\n",
        "# Check compression\n",
        "comparison_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.737377Z",
          "iopub.execute_input": "2024-01-13T19:17:35.737859Z",
          "iopub.status.idle": "2024-01-13T19:17:35.754877Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.737826Z",
          "shell.execute_reply": "2024-01-13T19:17:35.753597Z"
        },
        "trusted": true,
        "id": "75s4RvRleBqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first essay text\n",
        "\n",
        "df_test_essays.text[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.758191Z",
          "iopub.execute_input": "2024-01-13T19:17:35.758516Z",
          "iopub.status.idle": "2024-01-13T19:17:35.764256Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.758487Z",
          "shell.execute_reply": "2024-01-13T19:17:35.763361Z"
        },
        "trusted": true,
        "id": "CZ0mlebMeBqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking length of the essays\n",
        "\n",
        "df_test_essays[\"text\"].apply(lambda x : len(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.765566Z",
          "iopub.execute_input": "2024-01-13T19:17:35.766104Z",
          "iopub.status.idle": "2024-01-13T19:17:35.779703Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.766070Z",
          "shell.execute_reply": "2024-01-13T19:17:35.778831Z"
        },
        "trusted": true,
        "id": "8lQLhhyTeBqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='289C4E'>3.2. Prompts Dataset üóûÔ∏è<font><a class='anchor' id='prompts'></a> [‚Üë](#top)"
      ],
      "metadata": {
        "id": "oyQRgFHQeBqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now explore the prompts dataset. We see that it only contains 2 entries, which means only 2 prompts or topics were created to produced several essays."
      ],
      "metadata": {
        "id": "162n6ZUxeBqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompts Dataset\n",
        "\n",
        "df_train_prompts = pd.read_csv('/content/drive/MyDrive/data_vlg /train_prompts.csv')\n",
        "print(df_train_prompts.info())\n",
        "\n",
        "df_train_prompts.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.781009Z",
          "iopub.execute_input": "2024-01-13T19:17:35.781408Z",
          "iopub.status.idle": "2024-01-13T19:17:35.810299Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.781373Z",
          "shell.execute_reply": "2024-01-13T19:17:35.808892Z"
        },
        "trusted": true,
        "id": "grHvRnL4eBqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compression\n",
        "\n",
        "# Compress dataframe\n",
        "df_train_prompts, comparison_df = compress(df_train_prompts, verbose=True)\n",
        "\n",
        "# Check compression\n",
        "comparison_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.811511Z",
          "iopub.execute_input": "2024-01-13T19:17:35.812278Z",
          "iopub.status.idle": "2024-01-13T19:17:35.829165Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.812248Z",
          "shell.execute_reply": "2024-01-13T19:17:35.828451Z"
        },
        "trusted": true,
        "id": "x_ElepXeeBqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first instruction given to students\n",
        "\n",
        "df_train_prompts.instructions[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.830380Z",
          "iopub.execute_input": "2024-01-13T19:17:35.830834Z",
          "iopub.status.idle": "2024-01-13T19:17:35.837472Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.830806Z",
          "shell.execute_reply": "2024-01-13T19:17:35.836719Z"
        },
        "trusted": true,
        "id": "k4-Zf6bIeBqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first text\n",
        "\n",
        "df_train_prompts.source_text[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.838665Z",
          "iopub.execute_input": "2024-01-13T19:17:35.839157Z",
          "iopub.status.idle": "2024-01-13T19:17:35.850388Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.839130Z",
          "shell.execute_reply": "2024-01-13T19:17:35.849136Z"
        },
        "trusted": true,
        "id": "XFELQ9AeeBqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the prompts in the test set seems to be well balanced. On the other hand, there are only 3 texts generated by AI. Therefore, it will ne necessary to add additional data for the training to balance the dataset."
      ],
      "metadata": {
        "id": "oWxRnzCveBqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Prompts\n",
        "\n",
        "# Set Figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create the count plot\n",
        "ax = sns.countplot(data=df_train_essays, x=\"prompt_id\", palette=\"viridis\")\n",
        "\n",
        "# Mapping x-axis labels\n",
        "ax.set_xticklabels([\"Student\", \"AI\"])\n",
        "\n",
        "# Obtaining and setting the count values\n",
        "abs_values = df_train_essays['prompt_id'].value_counts().values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values, fontsize=12)\n",
        "\n",
        "# Set title and labels with increased font sizes\n",
        "ax.set_title(\"Distribution of Prompt ID\", fontsize=16)\n",
        "ax.set_xlabel(\"Prompt ID\", fontsize=14)\n",
        "ax.set_ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:35.851925Z",
          "iopub.execute_input": "2024-01-13T19:17:35.852223Z",
          "iopub.status.idle": "2024-01-13T19:17:36.123479Z",
          "shell.execute_reply.started": "2024-01-13T19:17:35.852199Z",
          "shell.execute_reply": "2024-01-13T19:17:36.121890Z"
        },
        "trusted": true,
        "id": "-IhWIc0keBqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Generated Text\n",
        "\n",
        "# Set Figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create the count plot\n",
        "ax = sns.countplot(data=df_train_essays, x=\"generated\", palette=\"viridis\")\n",
        "\n",
        "# Mapping x-axis labels\n",
        "ax.set_xticklabels([\"Student\", \"AI\"])\n",
        "\n",
        "# Obtaining and setting the count values\n",
        "abs_values = df_train_essays['generated'].value_counts().values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values, fontsize=12)\n",
        "\n",
        "# Set title and labels with increased font sizes\n",
        "ax.set_title(\"Distribution of Generated Text\", fontsize=16)\n",
        "ax.set_xlabel(\"Generated Text\", fontsize=14)\n",
        "ax.set_ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:36.124889Z",
          "iopub.execute_input": "2024-01-13T19:17:36.125263Z",
          "iopub.status.idle": "2024-01-13T19:17:36.351696Z",
          "shell.execute_reply.started": "2024-01-13T19:17:36.125229Z",
          "shell.execute_reply": "2024-01-13T19:17:36.350137Z"
        },
        "trusted": true,
        "id": "8CNe9Mh1eBqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='289C4E'>5. External Essays üì§<font><a class='anchor' id='distext'></a> [‚Üë](#top)"
      ],
      "metadata": {
        "id": "Ne--y0UyeBqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the train set is imbalanced, we have the possibility to import external data. In our case we will use the [DAIGT](https://www.kaggle.com/datasets/thedrcat/daigt-proper-train-dataset/) which contains the original `train_essays.csv` file"
      ],
      "metadata": {
        "id": "U2-OhVFdeBqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='289C4E'>5.1. DAIGT Essay 1Ô∏è‚É£<font><a class='anchor' id='daigt'></a> [‚Üë](#top)"
      ],
      "metadata": {
        "id": "7CZY3q8HeBqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import external dataset\n",
        "\n",
        "ext1 = pd.read_csv('/content/drive/MyDrive/data_vlg /train_v2_drcat_02.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:36.353145Z",
          "iopub.execute_input": "2024-01-13T19:17:36.353520Z",
          "iopub.status.idle": "2024-01-13T19:17:38.354625Z",
          "shell.execute_reply.started": "2024-01-13T19:17:36.353487Z",
          "shell.execute_reply": "2024-01-13T19:17:38.353883Z"
        },
        "trusted": true,
        "id": "BaHxboBgeBqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext1.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.355843Z",
          "iopub.execute_input": "2024-01-13T19:17:38.356336Z",
          "iopub.status.idle": "2024-01-13T19:17:38.370035Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.356306Z",
          "shell.execute_reply": "2024-01-13T19:17:38.369011Z"
        },
        "trusted": true,
        "id": "B6_k6aQYeBqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicates\n",
        "\n",
        "# Get the number of rows with duplicates\n",
        "duplicates = ext1.duplicated().sum()\n",
        "\n",
        "# Print the number of rows before and after\n",
        "print(f\"Number of rows with duplicates: {duplicates}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.371560Z",
          "iopub.execute_input": "2024-01-13T19:17:38.372180Z",
          "iopub.status.idle": "2024-01-13T19:17:38.630948Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.372139Z",
          "shell.execute_reply": "2024-01-13T19:17:38.629729Z"
        },
        "trusted": true,
        "id": "PZN0OAxEeBqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compression\n",
        "\n",
        "# Compress dataframe\n",
        "ext1, comparison_df = compress(ext1, verbose=True)\n",
        "\n",
        "# Check compression\n",
        "comparison_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.632398Z",
          "iopub.execute_input": "2024-01-13T19:17:38.633631Z",
          "iopub.status.idle": "2024-01-13T19:17:38.656154Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.633589Z",
          "shell.execute_reply": "2024-01-13T19:17:38.654997Z"
        },
        "trusted": true,
        "id": "ysPbnaqyeBqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains several columns that will not be necessary for our specific problem. Therefore we will remove them and rename the `label` column to `generated`."
      ],
      "metadata": {
        "id": "8fpIHqFqeBqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Columns\n",
        "\n",
        "ext1.drop([\"RDizzl3_seven\", \"prompt_name\", \"source\", \"prompt_name\"], inplace=True, axis=1)\n",
        "\n",
        "ext1.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.657953Z",
          "iopub.execute_input": "2024-01-13T19:17:38.658376Z",
          "iopub.status.idle": "2024-01-13T19:17:38.670505Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.658340Z",
          "shell.execute_reply": "2024-01-13T19:17:38.669760Z"
        },
        "trusted": true,
        "id": "OT7lniGpeBqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename label column\n",
        "\n",
        "ext1.rename(columns = {\"label\":\"generated\"}, inplace=True)\n",
        "\n",
        "ext1.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.671792Z",
          "iopub.execute_input": "2024-01-13T19:17:38.673269Z",
          "iopub.status.idle": "2024-01-13T19:17:38.684364Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.673214Z",
          "shell.execute_reply": "2024-01-13T19:17:38.683593Z"
        },
        "trusted": true,
        "id": "0ow-Ys5EeBqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='289C4E'>5.2. Distribution ‚öñÔ∏è<font><a class='anchor' id='dist'></a> [‚Üë](#top)    "
      ],
      "metadata": {
        "id": "kmfur-MKeBqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now plot the distribution of the labels. We see that the dataset is imbalanced. However, in order to set a Neural Network baseline model, we will use the dataset as it is."
      ],
      "metadata": {
        "id": "xn6sGvh_eBqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Generated Text in the External Dataset\n",
        "\n",
        "# Set Figure\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create the count plot\n",
        "ax = sns.countplot(data=ext1, x=\"generated\", palette=\"viridis\")\n",
        "\n",
        "# Mapping x-axis labels\n",
        "ax.set_xticklabels([\"Student\", \"AI\"])\n",
        "\n",
        "# Obtaining and setting the count values\n",
        "abs_values = ext1['generated'].value_counts().values\n",
        "ax.bar_label(container=ax.containers[0], labels=abs_values, fontsize=12)\n",
        "\n",
        "# Set title and labels with increased font sizes\n",
        "ax.set_title(\"Distribution of Generated Text\", fontsize=16)\n",
        "ax.set_xlabel(\"Generated Text\", fontsize=14)\n",
        "ax.set_ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.685564Z",
          "iopub.execute_input": "2024-01-13T19:17:38.686413Z",
          "iopub.status.idle": "2024-01-13T19:17:38.909048Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.686382Z",
          "shell.execute_reply": "2024-01-13T19:17:38.906908Z"
        },
        "trusted": true,
        "id": "LlHax4bzeBqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='289C4E'>5.3. Wordcloud ü§º‚Äç<font><a class='anchor' id='wc'></a> [‚Üë](#top)    "
      ],
      "metadata": {
        "id": "ki09ptfOeBqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will go deeper in the analysis. We will plot the wordcloud an the list of most and less common words.\n",
        "\n",
        "We see that the most common words are tipically stopwords, which we could remove. Additionally some numbers appear, which are also not relevant and can be removed."
      ],
      "metadata": {
        "id": "wLaAtDdjeBqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot WordCloud\n",
        "\n",
        "# Create a 1x2 grid of subplots\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Generate WordCloud for label_value = 1 (subplot 1)\n",
        "generate_wordcloud_subplot(ext1, label_value=1, subplot_position=121, top_n = 10)\n",
        "\n",
        "# Generate WordCloud for label_value = 0 (subplot 2)\n",
        "generate_wordcloud_subplot(ext1, label_value=0, subplot_position=122, top_n = 10)\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between subplots\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:17:38.910581Z",
          "iopub.execute_input": "2024-01-13T19:17:38.911050Z",
          "iopub.status.idle": "2024-01-13T19:18:26.773041Z",
          "shell.execute_reply.started": "2024-01-13T19:17:38.911015Z",
          "shell.execute_reply": "2024-01-13T19:18:26.771382Z"
        },
        "trusted": true,
        "id": "zRMK4FZdeBqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several preprocessing steps that we will perform:\n",
        "\n",
        "* Clean text: lower text, removal of punctiation, extra spaces, whitespaces and numbers\n",
        "\n",
        "* Stopwords removal\n",
        "\n",
        "This will help to feed the model with mode relevant information."
      ],
      "metadata": {
        "id": "yE8rATFteBqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Replace actual newline and carriage return characters with whitespace\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = text.replace(\"\\r\", \" \")\n",
        "\n",
        "    # Drop punctuation\n",
        "    text = re.sub(r\"\\p{P}\", \" \", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    # Remove leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # Lower text\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the 'text' column in the DataFrame\n",
        "ext1['text'] = ext1['text'].apply(clean_text)\n",
        "\n",
        "# Change contractions\n",
        "contractions = {\n",
        "    r'\\b(can\\'t)\\b': 'cannot',\n",
        "    r'\\b(don\\'t)\\b': 'do not',\n",
        "    r'\\b(won\\'t)\\b': 'will not',\n",
        "}\n",
        "\n",
        "# Iterate through contractions and apply replacements to the entire DataFrame column\n",
        "for pattern, replacement in contractions.items():\n",
        "    ext1['text'] = ext1['text'].apply(lambda x: re.sub(pattern, replacement, x, flags=re.IGNORECASE))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:18:26.774165Z",
          "iopub.execute_input": "2024-01-13T19:18:26.774490Z",
          "iopub.status.idle": "2024-01-13T19:18:35.446762Z",
          "shell.execute_reply.started": "2024-01-13T19:18:26.774461Z",
          "shell.execute_reply": "2024-01-13T19:18:35.445504Z"
        },
        "trusted": true,
        "id": "TbxUPvXgeBqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As NLTK is not working in Kaggle. We set the stopwords list\n",
        "\n",
        "stopword_list = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "len(stopword_list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:18:35.447994Z",
          "iopub.execute_input": "2024-01-13T19:18:35.448316Z",
          "iopub.status.idle": "2024-01-13T19:18:35.463449Z",
          "shell.execute_reply.started": "2024-01-13T19:18:35.448286Z",
          "shell.execute_reply": "2024-01-13T19:18:35.461067Z"
        },
        "trusted": true,
        "id": "9N8ke9GZeBql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "\n",
        "def remove_custom_stopwords(sentence):\n",
        "    words = sentence.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stopword_list]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Apply the function to the 'text' column\n",
        "ext1['text'] = ext1['text'].apply(remove_custom_stopwords)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:18:35.470945Z",
          "iopub.execute_input": "2024-01-13T19:18:35.471453Z",
          "iopub.status.idle": "2024-01-13T19:19:03.442621Z",
          "shell.execute_reply.started": "2024-01-13T19:18:35.471413Z",
          "shell.execute_reply": "2024-01-13T19:19:03.441624Z"
        },
        "trusted": true,
        "id": "TvWxDZxweBql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check duplicates\n",
        "\n",
        "# Get the number of rows with duplicates\n",
        "duplicates = ext1.duplicated().sum()\n",
        "\n",
        "# Print the number of rows before and after\n",
        "print(f\"Number of rows with duplicates: {duplicates}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:03.444526Z",
          "iopub.execute_input": "2024-01-13T19:19:03.444853Z",
          "iopub.status.idle": "2024-01-13T19:19:03.601908Z",
          "shell.execute_reply.started": "2024-01-13T19:19:03.444822Z",
          "shell.execute_reply": "2024-01-13T19:19:03.600460Z"
        },
        "trusted": true,
        "id": "Mwfu71-AeBqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preprocessing if we plot the stopwords again, we see that the list of works looks more relevant and this will improve the results of our model."
      ],
      "metadata": {
        "id": "N0aSEjd2eBqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot WordCloud\n",
        "\n",
        "# Create a 1x2 grid of subplots\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Generate WordCloud for label_value = 1 (subplot 1)\n",
        "generate_wordcloud_subplot(ext1, label_value=1, subplot_position=121, top_n = 10)\n",
        "\n",
        "# Generate WordCloud for label_value = 0 (subplot 2)\n",
        "generate_wordcloud_subplot(ext1, label_value=0, subplot_position=122, top_n = 10)\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between subplots\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:03.603402Z",
          "iopub.execute_input": "2024-01-13T19:19:03.603874Z",
          "iopub.status.idle": "2024-01-13T19:19:50.969461Z",
          "shell.execute_reply.started": "2024-01-13T19:19:03.603840Z",
          "shell.execute_reply": "2024-01-13T19:19:50.967925Z"
        },
        "trusted": true,
        "id": "xzFRtPLreBqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset clean let's perform our training with an Neural Network model. First, let's make a copy of the final dataset."
      ],
      "metadata": {
        "id": "yojuqwVteBqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the final_df as df_model\n",
        "\n",
        "df_model = ext1.copy()\n",
        "\n",
        "df_model.generated.value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:50.970819Z",
          "iopub.execute_input": "2024-01-13T19:19:50.971165Z",
          "iopub.status.idle": "2024-01-13T19:19:50.982254Z",
          "shell.execute_reply.started": "2024-01-13T19:19:50.971141Z",
          "shell.execute_reply": "2024-01-13T19:19:50.980872Z"
        },
        "trusted": true,
        "id": "qqsvIItheBqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will split the dataset in train, test and validation. We will do it after shuffling it, so that we get a good label distribution."
      ],
      "metadata": {
        "id": "XnfqTxFXeBqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a shuffled df for a good labels distribution\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random_seed = 42\n",
        "\n",
        "print(\"Before shuffling:\", df_model.shape)\n",
        "\n",
        "# Shuffle the DataFrame with the specified random seed\n",
        "shuffled_df = df_model.sample(frac=1, random_state=random_seed)\n",
        "\n",
        "print(\"After shuffling:\", df_model.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:50.983613Z",
          "iopub.execute_input": "2024-01-13T19:19:50.983958Z",
          "iopub.status.idle": "2024-01-13T19:19:51.002186Z",
          "shell.execute_reply.started": "2024-01-13T19:19:50.983928Z",
          "shell.execute_reply": "2024-01-13T19:19:51.000338Z"
        },
        "trusted": true,
        "id": "haYIfXFneBqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/val/test split\n",
        "X = shuffled_df[\"text\"]\n",
        "y = shuffled_df[\"generated\"]\n",
        "\n",
        "\n",
        "# Split the data into train, validation, and test sets (80% train, 15% validation, 15% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_seed)\n",
        "\n",
        "# Display the shapes of the train, validation, and test sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_validation shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_validation shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:51.003945Z",
          "iopub.execute_input": "2024-01-13T19:19:51.004315Z",
          "iopub.status.idle": "2024-01-13T19:19:51.024981Z",
          "shell.execute_reply.started": "2024-01-13T19:19:51.004282Z",
          "shell.execute_reply": "2024-01-13T19:19:51.023211Z"
        },
        "trusted": true,
        "id": "_1SG3E-heBqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we see the distributions of the labels, we can appreciate a similar distribution in each set, which will help to a better performance of the model."
      ],
      "metadata": {
        "id": "ey47SJTReBqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get label counts for train, validation, and test data\n",
        "train_label_counts = y_train.value_counts()\n",
        "val_label_counts = y_val.value_counts()\n",
        "test_label_counts = y_test.value_counts()\n",
        "\n",
        "# Define custom labels for visualization\n",
        "custom_labels = {0: 'Student', 1: 'AI'}\n",
        "\n",
        "# Replace labels for visualization purposes\n",
        "train_labels_visual = train_label_counts.rename(custom_labels)\n",
        "val_labels_visual = val_label_counts.rename(custom_labels)\n",
        "test_labels_visual = test_label_counts.rename(custom_labels)\n",
        "\n",
        "# Define custom colors for each label\n",
        "label_colors = {'Student': '#33FF57', 'AI': '#FF5733'}\n",
        "\n",
        "# Create subplots with 1 row and 3 columns\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Train data distribution\n",
        "wedges, texts, autotexts = axes[0].pie(train_labels_visual, labels=train_labels_visual.index, autopct='%1.1f%%', colors=[label_colors[label] for label in train_labels_visual.index])\n",
        "axes[0].set_title('Train Data Distribution')\n",
        "\n",
        "# Subplot 2: Validation data distribution\n",
        "wedges, texts, autotexts = axes[1].pie(val_labels_visual, labels=val_labels_visual.index, autopct='%1.1f%%', colors=[label_colors[label] for label in val_labels_visual.index])\n",
        "axes[1].set_title('Validation Data Distribution')\n",
        "\n",
        "# Subplot 3: Test data distribution\n",
        "wedges, texts, autotexts = axes[2].pie(test_labels_visual, labels=test_labels_visual.index, autopct='%1.1f%%', colors=[label_colors[label] for label in test_labels_visual.index])\n",
        "axes[2].set_title('Test Data Distribution')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:51.026596Z",
          "iopub.execute_input": "2024-01-13T19:19:51.027087Z",
          "iopub.status.idle": "2024-01-13T19:19:51.401663Z",
          "shell.execute_reply.started": "2024-01-13T19:19:51.027049Z",
          "shell.execute_reply": "2024-01-13T19:19:51.400879Z"
        },
        "trusted": true,
        "id": "_CJePluYeBqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the vestorization we will use the **TextVectorization** layer from TensorFlow. This process prepares text data for input into a machine learning model by converting text into numerical representations that the model can work with."
      ],
      "metadata": {
        "id": "mcahiWD9eBqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the max vocaulary size\n",
        "\n",
        "text_vectorizer = TextVectorization(split=\"whitespace\",\n",
        "                                    output_mode=\"int\")\n",
        "\n",
        "# Fit the text vectorizer\n",
        "text_vectorizer.adapt(X)\n",
        "\n",
        "# Get the number of unique tokens in the vocabulary\n",
        "vocab_size = len(text_vectorizer.get_vocabulary())\n",
        "\n",
        "# Print the vocabulary size\n",
        "print(\"Vocabulary size:\", vocab_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:51.402764Z",
          "iopub.execute_input": "2024-01-13T19:19:51.403177Z",
          "iopub.status.idle": "2024-01-13T19:19:57.039245Z",
          "shell.execute_reply.started": "2024-01-13T19:19:51.403151Z",
          "shell.execute_reply": "2024-01-13T19:19:57.038341Z"
        },
        "trusted": true,
        "id": "wfxo924eeBqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "\n",
        "# Set the maximum vocabulary size\n",
        "# max_vocab_size = 10000\n",
        "max_vocab_size = vocab_size\n",
        "\n",
        "# Calculate the maximum sequence length based on the average number of tokens in training data\n",
        "average_tokens_per_sequence = round(sum([len(text.split()) for text in X_train]) / len(X_train))\n",
        "\n",
        "# Create and configure the TextVectorization layer\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens=max_vocab_size,\n",
        "#     ngrams=(3,5),\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=average_tokens_per_sequence,\n",
        "    pad_to_max_tokens=True\n",
        ")\n",
        "\n",
        "# Adapt the TextVectorization layer to the training text\n",
        "if len(X_train) > 0:\n",
        "    text_vectorizer.adapt(X_train)\n",
        "else:\n",
        "    print(\"Warning: X_train is empty, adaptation skipped.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:19:57.040300Z",
          "iopub.execute_input": "2024-01-13T19:19:57.040770Z",
          "iopub.status.idle": "2024-01-13T19:20:02.574303Z",
          "shell.execute_reply.started": "2024-01-13T19:19:57.040742Z",
          "shell.execute_reply": "2024-01-13T19:20:02.573406Z"
        },
        "trusted": true,
        "id": "qon9eUwSeBqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After vectorization we will create an **Embedding** layer. This Embedding layer converts input text data (represented as indices or sequences of integers) into dense vectors of fixed size (output_dim) in the embedding space. These dense vectors serve as the input for subsequent layers in the neural network model, allowing the model to learn meaningful representations of words based on their contexts within the input sequences."
      ],
      "metadata": {
        "id": "sHzmn7OVeBqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_size,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=average_tokens_per_sequence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:20:02.575530Z",
          "iopub.execute_input": "2024-01-13T19:20:02.576612Z",
          "iopub.status.idle": "2024-01-13T19:20:02.595041Z",
          "shell.execute_reply.started": "2024-01-13T19:20:02.576559Z",
          "shell.execute_reply": "2024-01-13T19:20:02.593176Z"
        },
        "trusted": true,
        "id": "hnI4NFKweBqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our baseline model is set up for binary classification tasks where the input is text data, and the objective is to predict a binary outcome (Student or AI generated). The text is tokenized, embedded, and then processed through a simple neural network architecture for classification. We have added som callbacks for better performance."
      ],
      "metadata": {
        "id": "9PUlZCkXeBqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "keras_model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile model\n",
        "keras_model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of the model\n",
        "keras_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:20:02.596473Z",
          "iopub.execute_input": "2024-01-13T19:20:02.596929Z",
          "iopub.status.idle": "2024-01-13T19:20:02.957238Z",
          "shell.execute_reply.started": "2024-01-13T19:20:02.596894Z",
          "shell.execute_reply": "2024-01-13T19:20:02.955738Z"
        },
        "trusted": true,
        "id": "63HYbwcjeBqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "\n",
        "callbacks = [ModelCheckpoint(filepath='keras_model', save_best_only=True, save_format='tf'),\n",
        "             EarlyStopping(patience=7, monitor='val_loss', restore_best_weights = True),\n",
        "             ReduceLROnPlateau(factor=0.2, patience=5, monitor='val_loss'),\n",
        "             CSVLogger('keras_training_log.csv')]\n",
        "\n",
        "\n",
        "keras_model_history = keras_model.fit(X_train,\n",
        "                                      y_train,\n",
        "                                      epochs=20,\n",
        "                                      validation_data=(X_val, y_val),\n",
        "                                      callbacks=callbacks,\n",
        "                                     # batch_size=32\n",
        "                                     )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:20:02.959514Z",
          "iopub.execute_input": "2024-01-13T19:20:02.959896Z",
          "iopub.status.idle": "2024-01-13T19:42:46.516273Z",
          "shell.execute_reply.started": "2024-01-13T19:20:02.959869Z",
          "shell.execute_reply": "2024-01-13T19:42:46.515075Z"
        },
        "trusted": true,
        "id": "BvSQdXVBeBqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This **learning curves** helps in assessing the model's training progress and observing the trend of both training and validation losses over epochs. We can appreciate that the learning curves are shwoing a good trend and low values. However, the fit very fast and show some overfitting."
      ],
      "metadata": {
        "id": "icIMwd-IeBqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curves\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(keras_model_history.history['loss'], label='Training Loss')\n",
        "plt.plot(keras_model_history.history['val_loss'], label='Validation Loss')\n",
        "\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "\n",
        "# Set y-axis lower limit to 0.5\n",
        "plt.ylim(top=0.5)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:42:46.517344Z",
          "iopub.execute_input": "2024-01-13T19:42:46.517690Z",
          "iopub.status.idle": "2024-01-13T19:43:25.958241Z",
          "shell.execute_reply.started": "2024-01-13T19:42:46.517660Z",
          "shell.execute_reply": "2024-01-13T19:43:25.957170Z"
        },
        "trusted": true,
        "id": "aKpL12s6eBqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **confusion matrix** aids in understanding the model's accuracy in predicting each class and the misclassifications made by the model on the test dataset (X_test). In our case we get excellent results with low amount of FP/FN."
      ],
      "metadata": {
        "id": "xqGczTc4eBq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on input data (X_test) in form of probabilities\n",
        "\n",
        "keras_probabilities = keras_model.predict(X_test)\n",
        "keras_probabilities[:5]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:25.959458Z",
          "iopub.execute_input": "2024-01-13T19:43:25.959746Z",
          "iopub.status.idle": "2024-01-13T19:43:27.383469Z",
          "shell.execute_reply.started": "2024-01-13T19:43:25.959722Z",
          "shell.execute_reply": "2024-01-13T19:43:27.381996Z"
        },
        "trusted": true,
        "id": "4fdQTQiHeBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "\n",
        "# squeeze removes single dimensions\n",
        "keras_prediction = tf.squeeze(tf.round(keras_probabilities))\n",
        "keras_prediction[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:27.384967Z",
          "iopub.execute_input": "2024-01-13T19:43:27.385271Z",
          "iopub.status.idle": "2024-01-13T19:43:27.398387Z",
          "shell.execute_reply.started": "2024-01-13T19:43:27.385248Z",
          "shell.execute_reply": "2024-01-13T19:43:27.396811Z"
        },
        "trusted": true,
        "id": "SYYqp23FeBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "\n",
        "keras_cm = confusion_matrix(y_test, keras_prediction)\n",
        "keras_cm_plot =ConfusionMatrixDisplay(confusion_matrix=keras_cm)\n",
        "\n",
        "keras_cm_plot.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:27.400154Z",
          "iopub.execute_input": "2024-01-13T19:43:27.400812Z",
          "iopub.status.idle": "2024-01-13T19:43:27.633430Z",
          "shell.execute_reply.started": "2024-01-13T19:43:27.400771Z",
          "shell.execute_reply": "2024-01-13T19:43:27.632101Z"
        },
        "trusted": true,
        "id": "rcZu-KXQeBq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This **classification report** evaluates the model's performance using classification metrics and provides insights into its precision, recall, and f1-score for each class, helping to assess how well the model performs in classifying instances in the test dataset (X_test). In our case we get excellent results in all the parameters (precision, recall, f1-score and accuracy)"
      ],
      "metadata": {
        "id": "YNWnb_e2eBq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions from the model on the test set\n",
        "y_pred = keras_model.predict(X_test)\n",
        "\n",
        "# Converting probabilities to classes (assuming a threshold of 0.5)\n",
        "y_pred_classes = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Printing the classification report\n",
        "print(classification_report(y_test, y_pred_classes))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:27.635334Z",
          "iopub.execute_input": "2024-01-13T19:43:27.635651Z",
          "iopub.status.idle": "2024-01-13T19:43:28.802002Z",
          "shell.execute_reply.started": "2024-01-13T19:43:27.635609Z",
          "shell.execute_reply": "2024-01-13T19:43:28.800859Z"
        },
        "trusted": true,
        "id": "HyD4gGD8eBq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **ROC curve**, illustrates the trade-off between the true positive rate and false positive rate across different thresholds. The AUC value quantifies the overall performance of the model in distinguishing between the positive and negative classes, with a higher AUC indicating better performance. In our case, again the results are excellent. Note that this is the metric use to evaluate the model performance."
      ],
      "metadata": {
        "id": "nJyKAcYjeBq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUC -  ROC Curve\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "# Calculate AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "\n",
        "# Set labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "# Set title and legend\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:28.803575Z",
          "iopub.execute_input": "2024-01-13T19:43:28.803972Z",
          "iopub.status.idle": "2024-01-13T19:43:29.083177Z",
          "shell.execute_reply.started": "2024-01-13T19:43:28.803942Z",
          "shell.execute_reply": "2024-01-13T19:43:29.081053Z"
        },
        "trusted": true,
        "id": "y8eQWbPkeBq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **precision-recall curve** illustrates the trade-off between precision and recall for different probability thresholds. A higher AUC value indicates better performance of the model in terms of both precision and recall for different classification thresholds. This curve provides valuable insights into the model's performance, especially in scenarios with imbalanced class distributions. In our case, again the results are excellent."
      ],
      "metadata": {
        "id": "2ATFenybeBq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precission-recall curve\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, keras_probabilities)\n",
        "\n",
        "# Calculate AUC for precision-recall curve\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot precision-recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='orange', lw=2, label='Precision-Recall curve (AUC = {:.2f})'.format(pr_auc))\n",
        "\n",
        "# Set labels\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "\n",
        "# Set title and legend\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:29.084539Z",
          "iopub.execute_input": "2024-01-13T19:43:29.084880Z",
          "iopub.status.idle": "2024-01-13T19:43:29.360334Z",
          "shell.execute_reply.started": "2024-01-13T19:43:29.084851Z",
          "shell.execute_reply": "2024-01-13T19:43:29.358471Z"
        },
        "trusted": true,
        "id": "Q2-cUr7ueBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's submit our baseline model predictions!!"
      ],
      "metadata": {
        "id": "sYWH88x1eBq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = keras_model.predict(df_test_essays[\"text\"])\n",
        "test_prediction"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:29.361598Z",
          "iopub.execute_input": "2024-01-13T19:43:29.362020Z",
          "iopub.status.idle": "2024-01-13T19:43:29.456459Z",
          "shell.execute_reply.started": "2024-01-13T19:43:29.361986Z",
          "shell.execute_reply": "2024-01-13T19:43:29.455061Z"
        },
        "trusted": true,
        "id": "JoSALlIjeBq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store the submission\n",
        "submission_df = df_test_essays[[\"id\"]].copy()\n",
        "\n",
        "# Add the formatted predictions to the submission DataFrame\n",
        "submission_df[\"generated\"] = test_prediction.squeeze()\n",
        "\n",
        "# Save Submission\n",
        "submission_df.to_csv('submission.csv',index=False)\n",
        "\n",
        "# Display the first 2 rows of the submission DataFrame\n",
        "submission_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-13T19:43:29.458082Z",
          "iopub.execute_input": "2024-01-13T19:43:29.458480Z",
          "iopub.status.idle": "2024-01-13T19:43:29.475300Z",
          "shell.execute_reply.started": "2024-01-13T19:43:29.458446Z",
          "shell.execute_reply": "2024-01-13T19:43:29.473714Z"
        },
        "trusted": true,
        "id": "3FZ1iGiHeBq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5ZrWGyc1NKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}